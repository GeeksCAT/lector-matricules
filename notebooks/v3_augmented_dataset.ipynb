{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71e157df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f206d455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root directory: /home/noone/smartcatalonia-2021/lector-matricules\n"
     ]
    }
   ],
   "source": [
    "# Set base image directory\n",
    "os.chdir(\"../\")\n",
    "root = os.getcwd()\n",
    "base_imdir = os.path.join(root,\"pipeline-check\")\n",
    "print(\"Root directory: {}\".format(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615688a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
      "warning: no common commits\n",
      "remote: Enumerating objects: 4357, done.\u001b[K\n",
      "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
      "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
      "remote: Total 4357 (delta 37), reused 45 (delta 18), pack-reused 4267\u001b[K\n",
      "Receiving objects: 100% (4357/4357), 8.06 MiB | 4.99 MiB/s, done.\n",
      "Resolving deltas: 100% (2885/2885), done.\n",
      "From https://github.com/ultralytics/yolov5\n",
      " * branch              HEAD       -> FETCH_HEAD\n",
      "fatal: refusing to merge unrelated histories\n",
      "/home/noone/smartcatalonia-2021/lector-matricules/yolov5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(root)\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "!git pull https://github.com/ultralytics/yolov5 # update repo\n",
    "%cd yolov5\n",
    "%pip install -qr requirements.txt  # install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ce28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install kaggle package for dataset downloading\n",
    "!pip install kaggle --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f04252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading car-plate-detection.zip to /home/noone/smartcatalonia-2021/lector-matricules/datasets/car-plate-detection\n",
      " 99%|███████████████████████████████████████▊| 202M/203M [00:18<00:00, 11.8MB/s]\n",
      "100%|████████████████████████████████████████| 203M/203M [00:18<00:00, 11.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(root)\n",
    "\n",
    "if not os.path.isdir(\"datasets\"):\n",
    "    os.mkdir(\"datasets\")\n",
    "\n",
    "os.chdir(\"datasets\")\n",
    "\n",
    "# Download kaggle dataset for license plate detection\n",
    "if not os.path.isdir(\"car-plate-detection\"):\n",
    "    os.mkdir(\"car-plate-detection\")\n",
    "    os.chdir(\"car-plate-detection\")\n",
    "    !kaggle datasets download -d andrewmvd/car-plate-detection\n",
    "    # Extract the files\n",
    "    !unzip -q car-plate-detection.zip\n",
    "    !rm car-plate-detection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c580a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read xml file into a dictionary\n",
    "\n",
    "# Skip if annotations.csv exists\n",
    "if not os.path.isfile(\"annotations.csv\"):\n",
    "\n",
    "    # Set the working paths\n",
    "    data_path = os.path.join(root,\"datasets\",\"car-plate-detection\")\n",
    "    img_path = os.path.join(data_path,\"images\")\n",
    "    ann_path = os.path.join(data_path,\"annotations\")\n",
    "    label_path = os.path.join(data_path,\"labels\")\n",
    "\n",
    "    # Do a swipe and get all the xml files with annotations\n",
    "    (_,_,xmlfiles) = next(os.walk(ann_path))\n",
    "\n",
    "    os.chdir(ann_path)\n",
    "    ann_dict = {\"filename\": [],\n",
    "                \"imagepath\": [],\n",
    "                \"labelpath\": [],\n",
    "                \"xmin\": [],\n",
    "                \"xmax\": [],\n",
    "                \"ymin\": [],\n",
    "                \"ymax\": [],\n",
    "                \"height\": [],\n",
    "                \"width\":[],\n",
    "                \"x\": [],\n",
    "                \"y\": []\n",
    "               }\n",
    "\n",
    "    # Enter each xml file discovered, get some data and store it in the dictionary\n",
    "    for xmlfile in xmlfiles:\n",
    "        with open(xmlfile) as file:\n",
    "            data = file.read()\n",
    "\n",
    "            # String extraction of the important data\n",
    "            filename = data.split(\"<filename>\")[-1].split(\"</filename>\")[0].split(\".png\")[0]\n",
    "            imagepath = os.path.join(img_path,filename)+\".png\"\n",
    "            labelpath = os.path.join(label_path,filename)+\".txt\"\n",
    "            xmin = int( data.split(\"<xmin>\")[-1].split(\"</xmin>\")[0] )\n",
    "            xmax = int( data.split(\"<xmax>\")[-1].split(\"</xmax>\")[0] )\n",
    "            ymin = int( data.split(\"<ymin>\")[-1].split(\"</ymin>\")[0] )\n",
    "            ymax = int( data.split(\"<ymax>\")[-1].split(\"</ymax>\")[0] ) \n",
    "            im_width = int( data.split(\"<width>\")[-1].split(\"</width>\")[0] )\n",
    "            im_height = int( data.split(\"<height>\")[-1].split(\"</height>\")[0] )\n",
    "\n",
    "\n",
    "            # Normalized center of the bounding box in both axis\n",
    "            x = ((xmax-xmin)/2 + xmin) / im_width\n",
    "            y = ((ymax-ymin)/2 + ymin) / im_height\n",
    "\n",
    "            # Normalized height and width\n",
    "            width = (xmax-xmin) / im_width\n",
    "            height = (ymax-ymin) / im_height\n",
    "\n",
    "            # Writing into dictionary\n",
    "            ann_dict[\"filename\"].append(filename)\n",
    "            ann_dict[\"imagepath\"].append(imagepath)\n",
    "            ann_dict[\"labelpath\"].append(labelpath)\n",
    "            ann_dict[\"xmin\"].append(xmin)\n",
    "            ann_dict[\"xmax\"].append(xmax)\n",
    "            ann_dict[\"ymin\"].append(ymin)\n",
    "            ann_dict[\"ymax\"].append(ymax)\n",
    "            ann_dict[\"x\"].append(x)\n",
    "            ann_dict[\"y\"].append(y)\n",
    "            ann_dict[\"width\"].append(width)\n",
    "            ann_dict[\"height\"].append(height)\n",
    "            \n",
    "    # Convert dictionary to DF and export as CSV\n",
    "    os.chdir(data_path)\n",
    "    ann_df = pd.DataFrame.from_dict(ann_dict)\n",
    "    ann_df.to_csv(\"annotations.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c56270b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>class</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars310</td>\n",
       "      <td>license plate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.490833</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.178333</td>\n",
       "      <td>0.090395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cars378</td>\n",
       "      <td>license plate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.372964</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.146580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cars258</td>\n",
       "      <td>license plate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.781955</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.180451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cars33</td>\n",
       "      <td>license plate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.502222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars152</td>\n",
       "      <td>license plate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.311563</td>\n",
       "      <td>0.903333</td>\n",
       "      <td>0.229122</td>\n",
       "      <td>0.086667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Cars269</td>\n",
       "      <td>license plate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321250</td>\n",
       "      <td>0.693333</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>Cars57</td>\n",
       "      <td>license plate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685615</td>\n",
       "      <td>0.737603</td>\n",
       "      <td>0.118329</td>\n",
       "      <td>0.136364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Cars249</td>\n",
       "      <td>license plate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>0.878543</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.072874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>Cars128</td>\n",
       "      <td>license plate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522500</td>\n",
       "      <td>0.528889</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Cars116</td>\n",
       "      <td>license plate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.700301</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.087349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename          label class         x         y     width    height\n",
       "0    Cars310  license plate     0  0.490833  0.740113  0.178333  0.090395\n",
       "1    Cars378  license plate     0  0.465000  0.372964  0.340000  0.146580\n",
       "2    Cars258  license plate     0  0.485000  0.781955  0.180000  0.180451\n",
       "3     Cars33  license plate     0  0.500000  0.500000  0.530000  0.502222\n",
       "4    Cars152  license plate     0  0.311563  0.903333  0.229122  0.086667\n",
       "..       ...            ...   ...       ...       ...       ...       ...\n",
       "428  Cars269  license plate     0  0.321250  0.693333  0.092500  0.060000\n",
       "429   Cars57  license plate     0  0.685615  0.737603  0.118329  0.136364\n",
       "430  Cars249  license plate     0  0.817500  0.878543  0.135000  0.072874\n",
       "431  Cars128  license plate     0  0.522500  0.528889  0.485000  0.480000\n",
       "432  Cars116  license plate     0  0.520000  0.700301  0.295000  0.087349\n",
       "\n",
       "[433 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.read_csv(\"annotations.csv\")\n",
    "\n",
    "# Add the label column, not really useful in this 1 class detection.\n",
    "label_df[\"label\"] = \"license plate\"\n",
    "\n",
    "# Encoding the classes as target numbers\n",
    "label_df[\"class\"] = label_df[\"label\"]                       # Copy the class column into a new one called target\n",
    "label_df[\"class\"] = label_df[\"class\"].astype(\"category\")   # Change target column data type to categorical data\n",
    "labels_mapping = dict( enumerate(label_df['class'].cat.categories)) # Make a dictionary of the assigned labels to each target\n",
    "label_df[\"class\"] = label_df[\"class\"].cat.codes            # Assign a number to each category (one for each unique class)\n",
    "label_df[\"class\"] = label_df[\"class\"].astype(\"object\")     # Change target column data type to object (original type)\n",
    "\n",
    "# Reorder columns\n",
    "label_df = label_df[[\"filename\",\"label\",\"class\",\"x\",\"y\",\"width\",\"height\"]]\n",
    "\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11c73ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label creation\n",
    "\n",
    "\n",
    "if not os.path.isdir(label_path):\n",
    "    os.mkdir(label_path)\n",
    "    \n",
    "os.chdir(label_path)\n",
    "\n",
    "# We now have to create the label files in a yolo format, which is\n",
    "# a txt file named as the image, containing these columns\n",
    "# label x_center_normalized y_center_normalized width_normalized height_normalized\n",
    "\n",
    "\n",
    "for i in range(len(label_df)):\n",
    "    \n",
    "    # Get the filename without the image extension and add the txt extension\n",
    "    txt_file_name = ann_df[\"labelpath\"][i]\n",
    "    \n",
    "    with open(txt_file_name,\"w\") as txtfile:\n",
    "        txtfile.write(str(label_df[\"class\"][i])+\" \"+str(label_df[\"x\"][i])+\" \"+str(label_df[\"y\"][i])+\" \"+str(label_df[\"width\"][i])+\" \"+str(label_df[\"height\"][i]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a3c3037",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform0 = A.Compose([\n",
    "        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=True, p=1.0),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "transform1 = A.Compose([\n",
    "        A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), always_apply=True, p=1.0),\n",
    "        A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "\n",
    "for i in range(len(ann_df)):\n",
    "    image = cv2.imread(ann_df[\"imagepath\"][i])\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    transformed0 = transform0(image=image)[\"image\"]\n",
    "    transformed1 = transform1(image=image)[\"image\"]\n",
    "#     imagename = str(i)+ann_df[\"filename\"][i]+\".png\"\n",
    "    imagename = ann_df[\"imagepath\"][i]\n",
    "#     imagename = os.path.join(img_path,imagename)\n",
    "    cv2.imwrite(imagename,image)\n",
    "    \n",
    "#     labelname = str(i)+ann_df[\"filename\"][i]+\".txt\"\n",
    "    \n",
    "    label = ann_df[\"labelpath\"][i]\n",
    "#     shutil.copy2(ann_df[\"labelpath\"][i],label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dd0262",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagepath\")\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "transformed0 = transform0(image=image)[\"image\"]\n",
    "imagename = ann_df[\"imagepath\"][i]\n",
    "cv2.imwrite(imagename,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce3872e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train/val\n",
    "\n",
    "os.chdir(data_path)\n",
    "\n",
    "msk = np.random.rand(len(label_df)) < 0.8\n",
    "train = label_df[msk].reset_index(drop = True)\n",
    "train.to_csv(os.path.join(data_path, 'train_df.csv'),index = False)\n",
    "\n",
    "val = label_df[~msk].reset_index(drop = True)\n",
    "val.to_csv(os.path.join(data_path, 'val_df.csv'),index = False)\n",
    "\n",
    "\n",
    "# Define and create folders for image training data\n",
    "train_img_path = os.path.join(img_path,\"train\")\n",
    "val_img_path = os.path.join(img_path,\"val\")\n",
    "\n",
    "if not os.path.isdir(train_img_path):\n",
    "    os.mkdir(train_img_path)\n",
    "    \n",
    "    # Move files from image folder to each training or validation folder\n",
    "    for i in range(len(train)):\n",
    "        filename = train[\"filename\"][i]+\".png\"\n",
    "        filepath0 = os.path.join(img_path,filename)\n",
    "        filepath1 = os.path.join(train_img_path,filename)\n",
    "        os.replace(filepath0,filepath1)\n",
    "    \n",
    "if not os.path.isdir(val_img_path):\n",
    "    os.mkdir(val_img_path)\n",
    "    \n",
    "    # Move files from image folder to each training or validation folder\n",
    "    for i in range(len(val)):\n",
    "        filename = val[\"filename\"][i]+\".png\"\n",
    "        filepath0 = os.path.join(img_path,filename)\n",
    "        filepath1 = os.path.join(val_img_path,filename)\n",
    "        os.replace(filepath0,filepath1)\n",
    "    \n",
    "# Define and create folders for label training data\n",
    "train_label_path = os.path.join(label_path,\"train\")\n",
    "val_label_path = os.path.join(label_path,\"val\")\n",
    "\n",
    "if not os.path.isdir(train_label_path):\n",
    "    os.mkdir(train_label_path)\n",
    "    \n",
    "    # Move files from image folder to each training or validation folder\n",
    "    for i in range(len(train)):\n",
    "        filename = train[\"filename\"][i]+\".txt\"\n",
    "        filepath0 = os.path.join(label_path,filename)\n",
    "        filepath1 = os.path.join(train_label_path,filename)\n",
    "        os.replace(filepath0,filepath1)\n",
    "    \n",
    "if not os.path.isdir(val_label_path):\n",
    "    os.mkdir(val_label_path)\n",
    "    \n",
    "    # Move files from image folder to each training or validation folder\n",
    "    for i in range(len(val)):\n",
    "        filename = val[\"filename\"][i]+\".txt\"\n",
    "        filepath0 = os.path.join(label_path,filename)\n",
    "        filepath1 = os.path.join(val_label_path,filename)\n",
    "        os.replace(filepath0,filepath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cfb434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_dir = os.path.join(root,\"yolov5\")\n",
    "os.chdir(yolo_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0a36743",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create dataset configuration YAML file\n",
    "if not os.path.isfile(\"dataset.yaml\"):\n",
    "    with open(\"dataset.yaml\",\"w\") as file:\n",
    "        file.write(\"train: \"+train_img_path+\"\\n\")\n",
    "        file.write(\"val: \"+val_img_path+\"\\n\")\n",
    "        file.write(\"nc: 1\\n\")\n",
    "        file.write(\"names: [\"\"license_plate\"\"]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd30832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start tensorboard (optional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/\n",
    "\n",
    "!python train.py --img 640 --batch 16 --epochs 500 --data dataset.yaml --cfg models/yolov5s.yaml --name v2_simple_training --workers 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bca2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs/train/v2_simple_training3/weights/best.pt --img 640 --source /home/noone/smartcatalonia-2021/lector-matricules/pipeline-check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeab510",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python detect.py --weights runs/train/v2_simple_training3/weights/best.pt --img 640 --source https://www.youtube.com/watch?v=OsbQCYNIATo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9338a694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
